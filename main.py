import os
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta, timezone
import email.utils
from urllib.parse import quote
import requests
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import re
import time
import random
import string

# âœ… åˆå§‹åŒ–èªæ„æ¨¡å‹
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# âœ… ç›¸ä¼¼åº¦é–€æª»
SIMILARITY_THRESHOLD = 0.95

ACCESS_TOKEN = os.getenv('ACCESS_TOKEN')
print("âœ… Access Token å‰ 10 ç¢¼ï¼š", ACCESS_TOKEN[:10] if ACCESS_TOKEN else "æœªè¨­å®š")

CATEGORY_KEYWORDS = {
    "æ–°å…‰é‡‘æ§": ["æ–°å…‰é‡‘", "æ–°å…‰äººå£½", "æ–°å£½", "å³æ±é€²"],
    "å°æ–°é‡‘æ§": ["å°æ–°é‡‘", "å°æ–°äººå£½", "å°æ–°å£½", "å³æ±äº®"],
    "é‡‘æ§": ["é‡‘æ§", "é‡‘èæ§è‚¡", "ä¸­ä¿¡é‡‘", "ç‰å±±é‡‘", "æ°¸è±é‡‘", "åœ‹æ³°é‡‘", "å¯Œé‚¦é‡‘", "å°ç£é‡‘"],
    "ä¿éšª": ["ä¿éšª", "å£½éšª", "å¥åº·éšª", "æ„å¤–éšª", "äººå£½"],
    "å…¶ä»–": []
}

EXCLUDED_KEYWORDS = ['ä¿éšªå¥—', 'é¿å­•å¥—', 'ä¿éšªå¥—ä½¿ç”¨', 'å¤ªé™½äººå£½', 'å¤§è¥¿éƒ¨äººå£½', 'ç¾åœ‹æµ·å²¸ä¿éšª']

TW_TZ = timezone(timedelta(hours=8))
now = datetime.now(TW_TZ)
today = now.date()

# âœ… æ¨™é¡Œæ­£è¦åŒ–
def normalize_title(title):
    title = re.sub(r'[ï½œ|â€§\-ï¼â€“â€”~ï½].*$', '', title)  # ç§»é™¤åª’é«”å¾Œç¶´
    title = re.sub(r'<[^>]+>', '', title)            # ç§»é™¤ HTML æ¨™ç±¤
    title = re.sub(r'[^\w\u4e00-\u9fff\s]', '', title)  # ç§»é™¤éæ–‡å­—ç¬¦è™Ÿ
    title = re.sub(r'\s+', ' ', title)               # å¤šé¤˜ç©ºç™½
    return title.strip().lower()

def create_super_broken_url(long_url):
    """å‰µå»ºè¶…å¼·æ‰“æ–·çš„ç¶²å€ï¼Œé¿å…ä»»ä½•é è¦½å¯èƒ½"""
    try:
        # ä½¿ç”¨å¤šå€‹çŸ­ç¶²å€æœå‹™
        services = [
            f"http://tinyurl.com/api-create.php?url={quote(long_url, safe='')}",
            f"https://is.gd/create.php?format=simple&url={quote(long_url, safe='')}",
            f"http://v.gd/create.php?format=simple&url={quote(long_url, safe='')}"
        ]
        
        for api_url in services:
            try:
                res = requests.get(api_url, timeout=5)
                if res.status_code == 200 and res.text.startswith('http'):
                    short_url = res.text.strip()
                    # æ·»åŠ è¶…å¼·ç ´å£åƒæ•¸
                    timestamp = int(time.time())
                    random_id = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=12))
                    return f"{short_url}?ref=nb&t={timestamp}&id={random_id}&nopreview=1&cache={timestamp}&v=safe"
            except:
                continue
                
    except Exception as e:
        print(f"âš ï¸ çŸ­ç¶²å€æœå‹™å¤±æ•—: {e}")
    
    # å‚™ç”¨æ–¹æ¡ˆï¼šåŸç¶²å€åŠ å¼·åŠ›åƒæ•¸
    timestamp = int(time.time())
    random_id = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=15))
    separator = '&' if '?' in long_url else '?'
    return f"{long_url}{separator}utm_source=bot&t={timestamp}&id={random_id}&nopreview=true&safe=1"

def format_ultra_broken_url(url):
    """å°‡ç¶²å€æ‰“æ–·åˆ°æ¥µè‡´ï¼Œç¢ºä¿ä¸æœƒè§¸ç™¼é è¦½"""
    # ç§»é™¤å”è­°
    clean_url = url.replace('https://', '').replace('http://', '')
    
    # æ–¹æ³•1: æ¯å€‹ç‰¹æ®Šå­—ç¬¦éƒ½ç”¨ç©ºæ ¼åŒ…åœ
    broken_url = clean_url.replace('.', ' . ')
    broken_url = broken_url.replace('/', ' / ')
    broken_url = broken_url.replace('?', ' ? ')
    broken_url = broken_url.replace('&', ' & ')
    broken_url = broken_url.replace('=', ' = ')
    broken_url = broken_url.replace('-', ' - ')
    
    # æ–¹æ³•2: åœ¨åŸŸåä¸­é–“ä¹ŸåŠ å…¥ç©ºæ ¼
    parts = broken_url.split(' / ', 1)
    if len(parts) > 0:
        domain_part = parts[0]
        # åœ¨åŸŸåä¸­æ¯éš”4-6å€‹å­—ç¬¦åŠ ç©ºæ ¼
        domain_chars = list(domain_part.replace(' ', ''))
        spaced_domain = ''
        for i, char in enumerate(domain_chars):
            spaced_domain += char
            if i > 0 and (i + 1) % 5 == 0 and char not in [' ', '.']:
                spaced_domain += ' '
        
        if len(parts) > 1:
            broken_url = spaced_domain + ' / ' + parts[1]
        else:
            broken_url = spaced_domain
    
    return broken_url

def format_message_with_broken_url(title, source_name, url):
    """æ ¼å¼åŒ–è¨Šæ¯ï¼Œä½¿ç”¨å¤šé‡æ‰“æ–·æŠ€è¡“"""
    broken_url = format_ultra_broken_url(url)
    
    # åˆ†æˆå¤šè¡Œé¡¯ç¤ºï¼Œé€²ä¸€æ­¥é™ä½é è¦½é¢¨éšª
    url_lines = []
    words = broken_url.split()
    current_line = ""
    
    for word in words:
        if len(current_line + word) < 35:  # æ¯è¡Œæœ€å¤š35å­—ç¬¦
            current_line += word + " "
        else:
            if current_line.strip():
                url_lines.append(current_line.strip())
            current_line = word + " "
    
    if current_line.strip():
        url_lines.append(current_line.strip())
    
    # æ ¼å¼åŒ–å¤šè¡Œç¶²å€é¡¯ç¤º
    formatted_url_lines = '\n'.join([f"  {line}" for line in url_lines])
    
    return f"""ğŸ“° {title}
ğŸ“Œ ä¾†æºï¼š{source_name}
ğŸ”— ç¶²å€ (è¤‡è£½æ™‚ç§»é™¤æ‰€æœ‰ç©ºæ ¼)ï¼š
{formatted_url_lines}"""

def create_alternative_broken_url(url):
    """æ›¿ä»£çš„æ‰“æ–·æ–¹æ³• - ä½¿ç”¨ä¸­æ–‡ç¬¦è™Ÿ"""
    clean_url = url.replace('https://', '').replace('http://', '')
    
    # ä½¿ç”¨ä¸­æ–‡æ¨™é»ç¬¦è™Ÿæ‰“æ–·
    broken_url = clean_url.replace('.', 'ï¼')  # ä½¿ç”¨å…¨å½¢å¥è™Ÿ
    broken_url = broken_url.replace('/', 'ï¼')  # ä½¿ç”¨å…¨å½¢æ–œç·š
    broken_url = broken_url.replace('?', 'ï¼Ÿ')  # ä½¿ç”¨å…¨å½¢å•è™Ÿ
    broken_url = broken_url.replace('&', 'ï¼†')  # ä½¿ç”¨å…¨å½¢&
    broken_url = broken_url.replace('=', 'ï¼')  # ä½¿ç”¨å…¨å½¢ç­‰è™Ÿ
    
    return broken_url

def create_reverse_display_url(url):
    """åå‘é¡¯ç¤ºç¶²å€çš„éƒ¨åˆ†å…§å®¹"""
    clean_url = url.replace('https://', '').replace('http://', '')
    parts = clean_url.split('/')
    
    if len(parts) > 1:
        domain = parts[0]
        path = '/'.join(parts[1:])
        
        # åå‘é¡¯ç¤ºåŸŸå
        reversed_domain = domain[::-1]
        
        return f"ğŸŒ {reversed_domain} (åå‘) â†’ {path[:30]}..."
    
    return f"ğŸŒ {clean_url[::-1]} (åå‘é¡¯ç¤º)"

def format_creative_message(title, source_name, url):
    """å‰µæ„æ ¼å¼åŒ– - å¤šç¨®ç ´å£æ–¹æ³•çµ„åˆ"""
    
    # æ–¹æ³•é¸æ“‡ (å¯ä»¥éš¨æ©Ÿæˆ–æŒ‰é †åº)
    method = random.choice(['broken', 'chinese', 'reverse'])
    
    if method == 'broken':
        # è¶…å¼·æ‰“æ–·æ³•
        formatted_url = format_ultra_broken_url(url)
        url_display = f"ğŸ”— {formatted_url}\nğŸ’¡ è¤‡è£½æ™‚è«‹ç§»é™¤æ‰€æœ‰ç©ºæ ¼"
        
    elif method == 'chinese':
        # ä¸­æ–‡ç¬¦è™Ÿæ³•
        formatted_url = create_alternative_broken_url(url)
        url_display = f"ğŸ”— {formatted_url}\nğŸ’¡ è«‹å°‡å…¨å½¢ç¬¦è™Ÿæ”¹ç‚ºåŠå½¢"
        
    else:  # reverse
        # åå‘é¡¯ç¤ºæ³•
        formatted_url = create_reverse_display_url(url)
        url_display = f"{formatted_url}\nğŸ’¡ ç§è¨Šã€Œå®Œæ•´ç¶²å€ã€ç²å–æ­£å¸¸é€£çµ"
    
    return f"""ğŸ“° {title}
ğŸ“Œ ä¾†æºï¼š{source_name}
{url_display}"""

def classify_news(title):
    title = normalize_title(title)
    for category, keywords in CATEGORY_KEYWORDS.items():
        if any(kw.lower() in title for kw in keywords):
            return category
    return "å…¶ä»–"

def is_taiwan_news(source_name, link):
    taiwan_sources = [
        'å·¥å•†æ™‚å ±', 'ä¸­åœ‹æ™‚å ±', 'ç¶“æ¿Ÿæ—¥å ±', 'ä¸‰ç«‹æ–°èç¶²', 'è‡ªç”±æ™‚å ±', 'è¯åˆæ–°èç¶²',
        'é¡é€±åˆŠ', 'å°ç£é›…è™', 'é‰…äº¨ç¶²', 'ä¸­æ™‚æ–°èç¶²','Ettodayæ–°èé›²',
        'å¤©ä¸‹é›œèªŒ', 'å¥‡æ‘©æ–°è', 'ã€Šç¾ä»£ä¿éšªã€‹é›œèªŒ','é è¦‹é›œèªŒ'
    ]
    if any(taiwan_source in source_name for taiwan_source in taiwan_sources) and "é¦™æ¸¯ç¶“æ¿Ÿæ—¥å ±" not in source_name:
        return True
    if '.tw' in link:
        return True
    return False

def is_similar(title, known_titles_vecs):
    norm_title = normalize_title(title)
    vec = model.encode([norm_title])
    if not known_titles_vecs:
        return False
    sims = cosine_similarity(vec, known_titles_vecs)[0]
    return np.max(sims) >= SIMILARITY_THRESHOLD

def fetch_news():
    rss_urls = [
        "https://news.google.com/rss/search?q=æ–°å…‰é‡‘æ§+OR+æ–°å…‰äººå£½+OR+å°æ–°é‡‘æ§+OR+å°æ–°äººå£½+OR+å£½éšª+OR+é‡‘æ§+OR+äººå£½+OR+æ–°å£½+OR+å°æ–°å£½+OR+å³æ±é€²+OR+å³æ±äº®&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
        "https://news.google.com/rss/search?q=æ–°å…‰é‡‘æ§+OR+æ–°å…‰äººå£½+OR+æ–°å£½+OR+å³æ±é€²&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
        "https://news.google.com/rss/search?q=å°æ–°é‡‘æ§+OR+å°æ–°äººå£½+OR+å°æ–°å£½+OR+å³æ±äº®&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
        "https://news.google.com/rss/search?q=å£½éšª+OR+å¥åº·éšª+OR+æ„å¤–éšª+OR+äººå£½&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
        "https://news.google.com/rss/search?q=é‡‘æ§+OR+é‡‘èæ§è‚¡&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
    ]

    classified_news = {cat: [] for cat in CATEGORY_KEYWORDS}
    known_titles_vecs = []

    for rss_url in rss_urls:
        res = requests.get(rss_url)
        print(f"âœ… ä¾†æº: {rss_url} å›æ‡‰ç‹€æ…‹ï¼š{res.status_code}")
        if res.status_code != 200:
            continue

        root = ET.fromstring(res.content)
        items = root.findall(".//item")
        print(f"âœ… å¾ {rss_url} æŠ“åˆ° {len(items)} ç­†æ–°è")

        for item in items:
            title_elem = item.find('title')
            link_elem = item.find('link')
            pubDate_elem = item.find('pubDate')
            if title_elem is None or link_elem is None or pubDate_elem is None:
                continue

            title = title_elem.text.strip()
            link = link_elem.text.strip()
            pubDate_str = pubDate_elem.text.strip()
            if not title or title.startswith("Google ãƒ‹ãƒ¥ãƒ¼ã‚¹"):
                continue

            source_elem = item.find('source')
            source_name = source_elem.text.strip() if source_elem is not None else "æœªæ¨™ç¤º"
            pub_datetime = email.utils.parsedate_to_datetime(pubDate_str).astimezone(TW_TZ)

            if now - pub_datetime > timedelta(hours=24):
                continue
            if any(bad_kw in title for bad_kw in EXCLUDED_KEYWORDS):
                continue
            if not is_taiwan_news(source_name, link):
                continue
            if is_similar(title, known_titles_vecs):
                continue

            # ğŸ”‘ ä½¿ç”¨è¶…å¼·æ‰“æ–·ç¶²å€æ–¹æ³•
            broken_url = create_super_broken_url(link)
            formatted = format_message_with_broken_url(title, source_name, broken_url)
            
            category = classify_news(title)
            classified_news[category].append(formatted)

            # âœ… æ–°å¢å‘é‡ï¼ˆç”¨æ­£è¦åŒ–å¾Œæ¨™é¡Œï¼‰
            norm_title = normalize_title(title)
            known_titles_vecs.append(model.encode(norm_title))

    return classified_news

def send_message_by_category(news_by_category):
    max_length = 3500  # å› ç‚ºå¤šè¡Œæ ¼å¼éœ€è¦æ›´å¤šç©ºé–“
    no_news_categories = []

    for category, messages in news_by_category.items():
        if messages:
            title = f"ã€{today} æ¥­ä¼éƒ¨ ä»Šæ—¥ã€{category}ã€‘é‡é»æ–°èæ•´ç†ã€‘ å…±{len(messages)}å‰‡æ–°è"
            footer = "\n\nâš ï¸ ä½¿ç”¨ç¶²å€æ™‚è«‹ç§»é™¤æ‰€æœ‰ç©ºæ ¼ç¬¦è™Ÿ"
            
            content = "\n" + "â”€"*50 + "\n".join([f"\n{msg}\n" + "â”€"*50 for msg in messages])
            full_message = f"{title}{content}{footer}"
            
            # åˆ†æ®µç™¼é€é•·è¨Šæ¯
            for i in range(0, len(full_message), max_length):
                segment = full_message[i:i + max_length]
                if i > 0:
                    segment = f"ã€çºŒã€‘\n{segment}"
                broadcast_message(segment)
        else:
            no_news_categories.append(category)

    if no_news_categories:
        title = f"ã€{today} æ¥­ä¼éƒ¨ ä»Šæ—¥ç„¡ç›¸é—œæ–°èåˆ†é¡æ•´ç†ã€‘"
        content = "\n".join(f"ğŸ“‚ã€{cat}ã€‘ç„¡ç›¸é—œæ–°è" for cat in no_news_categories)
        broadcast_message(f"{title}\n\n{content}")

def broadcast_message(message):
    url = 'https://api.line.me/v2/bot/message/broadcast'
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {ACCESS_TOKEN}'
    }

    data = {
        "messages": [{
            "type": "text",
            "text": message
        }]
    }

    print(f"ğŸ“¤ ç™¼é€è¨Šæ¯ç¸½é•·ï¼š{len(message)} å­—å…ƒ")
    res = requests.post(url, headers=headers, json=data)
    print(f"ğŸ“¤ LINE å›å‚³ç‹€æ…‹ç¢¼ï¼š{res.status_code}")
    print("ğŸ“¤ LINE å›å‚³å…§å®¹ï¼š", res.text)

if __name__ == "__main__":
    news = fetch_news()
    if news:
        send_message_by_category(news)
    else:
        print("âš ï¸ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„æ–°èï¼Œä¸ç™¼é€ã€‚")



