import requests
import os
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta, timezone
import email.utils
from urllib.parse import quote, urlparse
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

ACCESS_TOKEN = os.getenv('ACCESS_TOKEN')
print("âœ… Access Token å‰ 10 ç¢¼ï¼š", ACCESS_TOKEN[:10] if ACCESS_TOKEN else "æœªè¨­å®š")

PREFERRED_SOURCES = ['å·¥å•†æ™‚å ±', 'ä¸­åœ‹æ™‚å ±', 'ç¶“æ¿Ÿæ—¥å ±', 'Ettodayæ–°èé›²', 'å·¥å•†æ™‚å ±ç¶²',
                     'ä¸­æ™‚æ–°èç¶²', 'å°ç£é›…è™å¥‡æ‘©', 'ç¶“æ¿Ÿæ—¥å ±ç¶²', 'é‰…äº¨ç¶²', 'è¯åˆæ–°èç¶²',
                     'é¡å‘¨åˆŠç¶²', 'è‡ªç”±è²¡ç¶“', 'ä¸­è¯æ—¥å ±', 'å°ç£æ–°ç”Ÿå ±', 'æ—ºå ±', 'ä¸‰ç«‹æ–°èç¶²',
                     'å¤©ä¸‹é›œèªŒ', 'å¥‡æ‘©æ–°è', 'ã€Šç¾ä»£ä¿éšªã€‹é›œèªŒ', 'MoneyDJ', 'é è¦‹é›œèªŒ',
                     'è‡ªç”±æ™‚å ±', 'Ettodayè²¡ç¶“é›²', 'é¡é€±åˆŠMirror Media', 'åŒ¯æµæ–°èç¶²',
                     'Newtalkæ–°è', 'å¥‡æ‘©è‚¡å¸‚', 'news.cnyes.com', 'ä¸­å¤®ç¤¾', 'æ°‘è¦–æ–°èç¶²',
                     'é¢¨å‚³åª’', 'CMoney', 'å¤§ç´€å…ƒ']

CATEGORY_DESCRIPTIONS = {
    "æ–°å…‰é‡‘æ§": "æ–°å…‰é‡‘ æ–°å…‰äººå£½ æ–°å…‰é‡‘æ§",
    "å°æ–°é‡‘æ§": "å°æ–°é‡‘ å°æ–°äººå£½ å°æ–°é‡‘æ§",
    "ä¿éšª": "ä¿éšª å£½éšª å¥åº·éšª æ„å¤–éšª ä¿éšªæ¥­",
    "é‡‘æ§": "é‡‘èæ§è‚¡ é‡‘èé›†åœ˜ é‡‘æ§ éŠ€è¡Œ",
    "å…¶ä»–": ""
}

EXCLUDED_KEYWORDS = ['ä¿éšªå¥—', 'é¿å­•å¥—', 'ä¿éšªå¥—ä½¿ç”¨']

TW_TZ = timezone(timedelta(hours=8))
today = datetime.now(TW_TZ).date()

vectorizer = TfidfVectorizer()
category_texts = list(CATEGORY_DESCRIPTIONS.values())
category_vectors = vectorizer.fit_transform(category_texts)

def classify_news(title):
    for category, keywords in CATEGORY_KEYWORDS.items():
        if any(kw in title for kw in keywords):
            print(f"News title: {title} matched category: {category}")  # é€™è¡Œå¯ä»¥å¹«åŠ©è¿½è¹¤
            return category
    return "å…¶ä»–"

def shorten_url(long_url):
    try:
        encoded_url = quote(long_url, safe='')
        api_url = f"http://tinyurl.com/api-create.php?url={encoded_url}"
        res = requests.get(api_url, timeout=5)
        if res.status_code == 200:
            return res.text.strip()
    except Exception as e:
        print("âš ï¸ çŸ­ç¶²å€å¤±æ•—ï¼š", e)
    return long_url


def extract_domain(url):
    try:
        parsed = urlparse(url)
        return parsed.netloc.replace('www.', '')
    except:
        return ""


def is_preferred_source(source_name, link, title):
    domain = extract_domain(link)
    return any(src in source_name or src in title or src in domain for src in PREFERRED_SOURCES)


def normalize_url(url):
    parsed = urlparse(url)
    return f"{parsed.netloc}{parsed.path}"


def fetch_news():
    keywords_list = [
        "æ–°å…‰é‡‘æ§ OR æ–°å…‰äººå£½",
        "å°æ–°é‡‘æ§ OR å°æ–°äººå£½",
        "å£½éšª OR å¥åº·éšª OR é‡‘æ§"
    ]

    rss_urls = [
        f"https://news.google.com/rss/search?q={quote(k)}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
        for k in keywords_list
    ]

    classified_news = {cat: [] for cat in CATEGORY_DESCRIPTIONS}
    seen_links = set()

    for rss_url in rss_urls:
        try:
            res = requests.get(rss_url)
            print(f"âœ… ä¾†æº: {rss_url} å›æ‡‰ç‹€æ…‹ï¼š{res.status_code}")
            if res.status_code != 200:
                continue
            root = ET.fromstring(res.content)
            items = root.findall(".//item")
            print(f"âœ… æŠ“åˆ° {len(items)} ç­†æ–°è")
        except Exception as e:
            print(f"âš ï¸ è§£æ RSS éŒ¯èª¤ï¼š{e}")
            continue

        for item in items:
            title_elem = item.find('title')
            link_elem = item.find('link')
            pubDate_elem = item.find('pubDate')
            if title_elem is None or link_elem is None or pubDate_elem is None:
                continue

            title = title_elem.text.strip()
            link = link_elem.text.strip()
            pubDate_str = pubDate_elem.text.strip()

            if not title or title.startswith("Google ãƒ‹ãƒ¥ãƒ¼ã‚¹"):
                continue

            norm_link = normalize_url(link)
            if norm_link in seen_links:
                continue
            seen_links.add(norm_link)

            source_elem = item.find('source')
            source_name = source_elem.text.strip() if source_elem is not None else "æœªæ¨™ç¤º"

            pub_datetime = email.utils.parsedate_to_datetime(pubDate_str).astimezone(TW_TZ)
            pub_date = pub_datetime.date()
            if pub_date != today:
                continue

            if any(bad_kw in title for bad_kw in EXCLUDED_KEYWORDS):
                continue

            if not is_preferred_source(source_name, link, title):
                continue

            short_link = shorten_url(link)
            category = classify_news(title)
            formatted = f"ğŸ“° {title}\nğŸ“Œ ä¾†æºï¼š{source_name}\nğŸ”— {short_link}"
            classified_news[category].append(formatted)

    news_text = f"ğŸ“… ä»Šæ—¥æ—¥æœŸï¼š{today.strftime('%Y-%m-%d')}\n\n"
    for cat in CATEGORY_DESCRIPTIONS:
        if classified_news[cat]:
            news_text += f"ğŸ“‚ã€{cat}ã€‘({len(classified_news[cat])}å‰‡)\n"
            for idx, item in enumerate(classified_news[cat], 1):
                news_text += f"{idx}. {item}\n\n"

    news_text += "ğŸ“ æœ¬æ–°èæ•´ç†è‡ª Google News RSSï¼Œé€£çµå·²è½‰ç‚ºçŸ­ç¶²å€ã€‚"
    print("âœ… ä»Šæ—¥æ–°èå…§å®¹ï¼š\n", news_text)
    return news_text.strip()


def broadcast_message(message):
    url = 'https://api.line.me/v2/bot/message/broadcast'
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {ACCESS_TOKEN}'
    }

    final_message = "ã€æ¥­ä¼éƒ¨ ä»Šæ—¥é‡é»æ–°èæ•´ç†ã€‘\n\n" + message
    data = {
        "messages": [{
            "type": "text",
            "text": final_message
        }]
    }

    print(f"ğŸ“¤ ç™¼é€è¨Šæ¯ç¸½é•·ï¼š{len(final_message)} å­—å…ƒ")
    res = requests.post(url, headers=headers, json=data)
    print(f"ğŸ“¤ LINE å›å‚³ç‹€æ…‹ç¢¼ï¼š{res.status_code}")
    print("ğŸ“¤ LINE å›å‚³å…§å®¹ï¼š", res.text)


if __name__ == "__main__":
    news = fetch_news()
    if news:
        broadcast_message(news)
    else:
        print("âš ï¸ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„æ–°èï¼Œä¸ç™¼é€ã€‚")
