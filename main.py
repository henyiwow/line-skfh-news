import os
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta, timezone
import email.utils
from urllib.parse import quote
import requests
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import re

# âœ… åˆå§‹åŒ–èªæ„æ¨¡å‹
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# âœ… ç›¸ä¼¼åº¦é–€æª»
SIMILARITY_THRESHOLD = 0.95

ACCESS_TOKEN = os.getenv('ACCESS_TOKEN')
print("âœ… Access Token å‰ 10 ç¢¼ï¼š", ACCESS_TOKEN[:10] if ACCESS_TOKEN else "æœªè¨­å®š")

CATEGORY_KEYWORDS = {
    "æ–°å…‰é‡‘æ§": ["æ–°å…‰é‡‘", "æ–°å…‰äººå£½", "æ–°å£½", "å³æ±é€²"],
    "å°æ–°é‡‘æ§": ["å°æ–°é‡‘", "å°æ–°äººå£½", "å°æ–°å£½", "å³æ±äº®"],
    "é‡‘æ§": ["é‡‘æ§", "é‡‘èæ§è‚¡", "ä¸­ä¿¡é‡‘", "ç‰å±±é‡‘", "æ°¸è±é‡‘", "åœ‹æ³°é‡‘", "å¯Œé‚¦é‡‘", "å°ç£é‡‘"],
    "ä¿éšª": ["ä¿éšª", "å£½éšª", "å¥åº·éšª", "æ„å¤–éšª", "äººå£½"],
    "å…¶ä»–": []
}

EXCLUDED_KEYWORDS = ['ä¿éšªå¥—', 'é¿å­•å¥—', 'ä¿éšªå¥—ä½¿ç”¨', 'å¤ªé™½äººå£½', 'å¤§è¥¿éƒ¨äººå£½', 'ç¾åœ‹æµ·å²¸ä¿éšª']

TW_TZ = timezone(timedelta(hours=8))
now = datetime.now(TW_TZ)
today = now.date()

# âœ… åˆ†é¡ emoji æ˜ å°„
CATEGORY_EMOJIS = {
    "æ–°å…‰é‡‘æ§": "ğŸŒŸ",
    "å°æ–°é‡‘æ§": "ğŸ¢", 
    "é‡‘æ§": "ğŸ¦",
    "ä¿éšª": "ğŸ›¡ï¸",
    "å…¶ä»–": "ğŸ“°"
}

# âœ… æ¨™é¡Œæ­£è¦åŒ–
def normalize_title(title):
    title = re.sub(r'[ï½œ|â€§\-ï¼â€“â€”~ï½].*$', '', title)  # ç§»é™¤åª’é«”å¾Œç¶´
    title = re.sub(r'<[^>]+>', '', title)            # ç§»é™¤ HTML æ¨™ç±¤
    title = re.sub(r'[^\w\u4e00-\u9fff\s]', '', title)  # ç§»é™¤éæ–‡å­—ç¬¦è™Ÿ
    title = re.sub(r'\s+', ' ', title)               # å¤šé¤˜ç©ºç™½
    return title.strip().lower()

# ğŸ”§ æ”¹é€²çš„çŸ­ç¶²å€æœå‹™ - æ”¯æ´å¤šç¨®æœå‹™
def shorten_url(long_url, service='tinyurl'):
    """
    æ”¯æ´å¤šç¨®çŸ­ç¶²å€æœå‹™
    service: 'tinyurl', 'is.gd', 'v.gd'
    """
    try:
        if service == 'tinyurl':
            encoded_url = quote(long_url, safe='')
            api_url = f"http://tinyurl.com/api-create.php?url={encoded_url}"
            res = requests.get(api_url, timeout=5)
            if res.status_code == 200 and res.text.startswith('http'):
                return res.text.strip()
        
        elif service == 'is.gd':
            api_url = "https://is.gd/create.php"
            data = {'format': 'simple', 'url': long_url}
            res = requests.post(api_url, data=data, timeout=5)
            if res.status_code == 200 and res.text.startswith('http'):
                return res.text.strip()
        
        elif service == 'v.gd':
            api_url = "https://v.gd/create.php"
            data = {'format': 'simple', 'url': long_url}
            res = requests.post(api_url, data=data, timeout=5)
            if res.status_code == 200 and res.text.startswith('http'):
                return res.text.strip()
                
    except Exception as e:
        print(f"âš ï¸ {service} çŸ­ç¶²å€å¤±æ•—ï¼š", e)
    
    return long_url

def classify_news(title):
    title = normalize_title(title)
    for category, keywords in CATEGORY_KEYWORDS.items():
        if any(kw.lower() in title for kw in keywords):
            return category
    return "å…¶ä»–"

def is_taiwan_news(source_name, link):
    taiwan_sources = [
        'å·¥å•†æ™‚å ±', 'ä¸­åœ‹æ™‚å ±', 'ç¶“æ¿Ÿæ—¥å ±', 'ä¸‰ç«‹æ–°èç¶²', 'è‡ªç”±æ™‚å ±', 'è¯åˆæ–°èç¶²',
        'é¡é€±åˆŠ', 'å°ç£é›…è™', 'é‰…äº¨ç¶²', 'ä¸­æ™‚æ–°èç¶²','Ettodayæ–°èé›²',
        'å¤©ä¸‹é›œèªŒ', 'å¥‡æ‘©æ–°è', 'ã€Šç¾ä»£ä¿éšªã€‹é›œèªŒ','é è¦‹é›œèªŒ'
    ]
    if any(taiwan_source in source_name for taiwan_source in taiwan_sources) and "é¦™æ¸¯ç¶“æ¿Ÿæ—¥å ±" not in source_name:
        return True
    if '.tw' in link:
        return True
    return False

def is_similar(title, known_titles_vecs):
    norm_title = normalize_title(title)
    vec = model.encode([norm_title])
    if not known_titles_vecs:
        return False
    sims = cosine_similarity(vec, known_titles_vecs)[0]
    return np.max(sims) >= SIMILARITY_THRESHOLD

def truncate_title(title, max_length=50):
    """æˆªæ–·éé•·çš„æ¨™é¡Œ"""
    if len(title) > max_length:
        return title[:max_length-3] + "..."
    return title

def format_time_ago(pub_datetime):
    """è¨ˆç®—ç™¼å¸ƒæ™‚é–“è·é›¢ç¾åœ¨å¤šä¹…"""
    time_diff = now - pub_datetime
    hours = int(time_diff.total_seconds() / 3600)
    
    if hours == 0:
        minutes = int(time_diff.total_seconds() / 60)
        return f"{minutes}åˆ†é˜å‰"
    elif hours < 24:
        return f"{hours}å°æ™‚å‰"
    else:
        return pub_datetime.strftime("%m/%d")

def fetch_news():
    rss_urls = [
        "https://news.google.com/rss/search?q=æ–°å…‰é‡‘æ§+OR+æ–°å…‰äººå£½+OR+å°æ–°é‡‘æ§+OR+å°æ–°äººå£½+OR+å£½éšª+OR+é‡‘æ§+OR+äººå£½+OR+æ–°å£½+OR+å°æ–°å£½+OR+å³æ±é€²+OR+å³æ±äº®&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
        "https://news.google.com/rss/search?q=æ–°å…‰é‡‘æ§+OR+æ–°å…‰äººå£½+OR+æ–°å£½+OR+å³æ±é€²&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
        "https://news.google.com/rss/search?q=å°æ–°é‡‘æ§+OR+å°æ–°äººå£½+OR+å°æ–°å£½+OR+å³æ±äº®&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
        "https://news.google.com/rss/search?q=å£½éšª+OR+å¥åº·éšª+OR+æ„å¤–éšª+OR+äººå£½&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
        "https://news.google.com/rss/search?q=é‡‘æ§+OR+é‡‘èæ§è‚¡&hl=zh-TW&gl=TW&ceid=TW:zh-Hant",
    ]

    classified_news = {cat: [] for cat in CATEGORY_KEYWORDS}
    known_titles_vecs = []

    for rss_url in rss_urls:
        res = requests.get(rss_url)
        print(f"âœ… ä¾†æº: {rss_url} å›æ‡‰ç‹€æ…‹ï¼š{res.status_code}")
        if res.status_code != 200:
            continue

        root = ET.fromstring(res.content)
        items = root.findall(".//item")
        print(f"âœ… å¾ {rss_url} æŠ“åˆ° {len(items)} ç­†æ–°è")

        for item in items:
            title_elem = item.find('title')
            link_elem = item.find('link')
            pubDate_elem = item.find('pubDate')
            if title_elem is None or link_elem is None or pubDate_elem is None:
                continue

            title = title_elem.text.strip()
            link = link_elem.text.strip()
            pubDate_str = pubDate_elem.text.strip()
            if not title or title.startswith("Google ãƒ‹ãƒ¥ãƒ¼ã‚¹"):
                continue

            source_elem = item.find('source')
            source_name = source_elem.text.strip() if source_elem is not None else "æœªæ¨™ç¤º"
            pub_datetime = email.utils.parsedate_to_datetime(pubDate_str).astimezone(TW_TZ)

            if now - pub_datetime > timedelta(hours=24):
                continue
            if any(bad_kw in title for bad_kw in EXCLUDED_KEYWORDS):
                continue
            if not is_taiwan_news(source_name, link):
                continue
            if is_similar(title, known_titles_vecs):
                continue

            # ğŸ”§ å˜—è©¦å¤šç¨®çŸ­ç¶²å€æœå‹™
            short_link = shorten_url(link, 'tinyurl')
            if short_link == link:  # å¦‚æœç¬¬ä¸€å€‹å¤±æ•—ï¼Œå˜—è©¦å…¶ä»–æœå‹™
                short_link = shorten_url(link, 'is.gd')
            if short_link == link:
                short_link = shorten_url(link, 'v.gd')
            
            category = classify_news(title)
            
            # ğŸ”§ å»ºç«‹æ–°èé …ç›®
            news_item = {
                'title': title,
                'source': source_name,
                'link': link,
                'short_link': short_link,
                'category': category,
                'pub_datetime': pub_datetime,
                'time_ago': format_time_ago(pub_datetime)
            }
            
            classified_news[category].append(news_item)

            # âœ… æ–°å¢å‘é‡ï¼ˆç”¨æ­£è¦åŒ–å¾Œæ¨™é¡Œï¼‰
            norm_title = normalize_title(title)
            known_titles_vecs.append(model.encode(norm_title))

    # ğŸ”§ æŒ‰ç™¼å¸ƒæ™‚é–“æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    for category in classified_news:
        classified_news[category].sort(key=lambda x: x['pub_datetime'], reverse=True)

    return classified_news

# ğŸ”§ Quick Reply è¨Šæ¯å»ºç«‹å‡½æ•¸
def create_quick_reply_message(news_items, category):
    """å»ºç«‹ Quick Reply æ ¼å¼çš„æ–°èè¨Šæ¯"""
    if not news_items:
        return None
    
    # ğŸ”§ å–å¾—åˆ†é¡ emoji
    category_emoji = CATEGORY_EMOJIS.get(category, "ğŸ“°")
    
    # ğŸ”§ å»ºç«‹æ–‡å­—å…§å®¹ï¼ˆé¡¯ç¤ºå‰10å‰‡æ–°èæ‘˜è¦ï¼‰
    text_lines = [
        f"ğŸ“… {today.strftime('%Y/%m/%d')} æ¥­ä¼éƒ¨ä»Šæ—¥æ–°è",
        f"{category_emoji} ã€{category}ã€‘å…± {len(news_items)} å‰‡æ–°è",
        ""
    ]
    
    # ğŸ”§ æ–°èæ‘˜è¦åˆ—è¡¨ï¼ˆæœ€å¤šé¡¯ç¤º10å‰‡ï¼‰
    display_count = min(10, len(news_items))
    for i, item in enumerate(news_items[:display_count], 1):
        truncated_title = truncate_title(item['title'], 45)
        text_lines.append(f"{i:2d}. {truncated_title}")
        text_lines.append(f"     ğŸ“Œ {item['source']} â€¢ {item['time_ago']}")
        text_lines.append("")
    
    if len(news_items) > 10:
        text_lines.append(f"â¬‡ï¸ é‚„æœ‰ {len(news_items) - 10} å‰‡æ–°èï¼Œé»æ“Šä¸‹æ–¹æŒ‰éˆ•æŸ¥çœ‹")
    
    text_content = "\n".join(text_lines)
    
    # ğŸ”§ å»ºç«‹ Quick Reply æŒ‰éˆ•ï¼ˆæœ€å¤š13å€‹ï¼‰
    quick_reply_items = []
    
    # æ–°èæŒ‰éˆ•ï¼ˆæœ€å¤š12å€‹æ–°è + 1å€‹ã€Œæ›´å¤šã€æŒ‰éˆ•ï¼‰
    button_count = min(12, len(news_items))
    for i, item in enumerate(news_items[:button_count]):
        quick_reply_items.append({
            "type": "action",
            "action": {
                "type": "uri",
                "label": f"ğŸ“° æ–°è{i+1}",
                "uri": item['link']
            }
        })
    
    # ğŸ”§ å¦‚æœæ–°èè¶…é12å‰‡ï¼Œæ·»åŠ ã€Œæ›´å¤šæ–°èã€æŒ‰éˆ•
    if len(news_items) > 12:
        # å¯ä»¥éˆæ¥åˆ°æ›´å®Œæ•´çš„æ–°èé é¢æˆ–ç™¼é€æ›´å¤šæ–°è
        quick_reply_items.append({
            "type": "action",
            "action": {
                "type": "postback",
                "label": "ğŸ“‹ æŸ¥çœ‹å…¨éƒ¨",
                "data": f"more_news_{category}",
                "displayText": f"æŸ¥çœ‹ã€{category}ã€‘å…¨éƒ¨æ–°è"
            }
        })
    
    return {
        "type": "text",
        "text": text_content,
        "quickReply": {
            "items": quick_reply_items
        }
    }

# ğŸ”§ å»ºç«‹å®Œæ•´æ–°èåˆ—è¡¨è¨Šæ¯ï¼ˆç•¶ç”¨æˆ¶é»æ“Šã€ŒæŸ¥çœ‹å…¨éƒ¨ã€æ™‚ï¼‰
def create_full_news_list(news_items, category):
    """å»ºç«‹å®Œæ•´çš„æ–°èåˆ—è¡¨ï¼ˆç´”æ–‡å­—æ ¼å¼ï¼‰"""
    category_emoji = CATEGORY_EMOJIS.get(category, "ğŸ“°")
    
    text_lines = [
        f"ğŸ“‹ ã€{category}ã€‘å®Œæ•´æ–°èåˆ—è¡¨",
        f"{category_emoji} å…± {len(news_items)} å‰‡æ–°è",
        f"ğŸ“… {today.strftime('%Y/%m/%d')}",
        "=" * 30,
        ""
    ]
    
    # ğŸ”§ é¡¯ç¤ºæ‰€æœ‰æ–°èï¼ˆæ¯4000å­—å…ƒåˆ†å‰²ä¸€æ¬¡ï¼‰
    current_length = len("\n".join(text_lines))
    max_length = 4000
    
    for i, item in enumerate(news_items, 1):
        news_text = f"{i:2d}. {item['title']}\n"
        news_text += f"     ğŸ“Œ {item['source']} â€¢ {item['time_ago']}\n"
        news_text += f"     ğŸ”— {item['short_link']}\n\n"
        
        # æª¢æŸ¥æ˜¯å¦æœƒè¶…éè¨Šæ¯é•·åº¦é™åˆ¶
        if current_length + len(news_text) > max_length:
            # å¦‚æœæœƒè¶…éï¼Œå…ˆç™¼é€ç•¶å‰å…§å®¹
            yield "\n".join(text_lines)
            # é‡ç½®ç‚ºæ–°çš„è¨Šæ¯
            text_lines = [f"ğŸ“‹ ã€{category}ã€‘æ–°èåˆ—è¡¨ (çºŒ)", ""]
            current_length = len("\n".join(text_lines))
        
        text_lines.append(news_text.strip())
        text_lines.append("")
        current_length += len(news_text)
    
    # ç™¼é€æœ€å¾Œä¸€æ®µå…§å®¹
    if len(text_lines) > 2:  # ç¢ºä¿ä¸æ˜¯ç©ºçš„
        yield "\n".join(text_lines)

def send_message_by_category(news_by_category):
    """ç™¼é€åˆ†é¡æ–°èè¨Šæ¯ï¼ˆQuick Reply æ ¼å¼ï¼‰"""
    no_news_categories = []

    for category, news_items in news_by_category.items():
        if news_items:
            # ğŸ”§ å»ºç«‹ Quick Reply è¨Šæ¯
            message = create_quick_reply_message(news_items, category)
            if message:
                broadcast_message_advanced(message)
                print(f"âœ… å·²ç™¼é€ã€{category}ã€‘æ–°èï¼Œå…± {len(news_items)} å‰‡")
        else:
            no_news_categories.append(category)

    # ğŸ”§ ç™¼é€ç„¡æ–°èåˆ†é¡çš„é€šçŸ¥
    if no_news_categories:
        title = f"ğŸ“… {today.strftime('%Y/%m/%d')} æ¥­ä¼éƒ¨æ–°èå ±å‘Š"
        content_lines = ["ä»¥ä¸‹åˆ†é¡ä»Šæ—¥ç„¡ç›¸é—œæ–°èï¼š", ""]
        for cat in no_news_categories:
            emoji = CATEGORY_EMOJIS.get(cat, "ğŸ“°")
            content_lines.append(f"{emoji} ã€{cat}ã€‘ç„¡ç›¸é—œæ–°è")
        
        no_news_message = {
            "type": "text", 
            "text": "\n".join([title] + [""] + content_lines)
        }
        broadcast_message_advanced(no_news_message)

def broadcast_message_advanced(message):
    """ç™¼é€é€²éšè¨Šæ¯æ ¼å¼"""
    url = 'https://api.line.me/v2/bot/message/broadcast'
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {ACCESS_TOKEN}'
    }

    data = {"messages": [message]}

    print(f"ğŸ“¤ ç™¼é€è¨Šæ¯é¡å‹ï¼š{message.get('type', 'unknown')}")
    res = requests.post(url, headers=headers, json=data)
    print(f"ğŸ“¤ LINE å›å‚³ç‹€æ…‹ç¢¼ï¼š{res.status_code}")
    if res.status_code != 200:
        print("ğŸ“¤ LINE å›å‚³å…§å®¹ï¼š", res.text)
    else:
        print("âœ… è¨Šæ¯ç™¼é€æˆåŠŸ")

# ğŸ”§ è™•ç† Postback äº‹ä»¶ï¼ˆç•¶ç”¨æˆ¶é»æ“Šã€ŒæŸ¥çœ‹å…¨éƒ¨ã€æ™‚ï¼‰
def handle_postback(event_data):
    """è™•ç† Postback äº‹ä»¶"""
    if event_data.startswith("more_news_"):
        category = event_data.replace("more_news_", "")
        
        # é‡æ–°ç²å–è©²åˆ†é¡çš„æ–°è
        news = fetch_news()
        if category in news and news[category]:
            # ç™¼é€å®Œæ•´æ–°èåˆ—è¡¨
            for message_text in create_full_news_list(news[category], category):
                simple_message = {"type": "text", "text": message_text}
                broadcast_message_advanced(simple_message)
        else:
            error_message = {
                "type": "text", 
                "text": f"âŒ æ‰¾ä¸åˆ°ã€{category}ã€‘çš„æ–°èè³‡æ–™"
            }
            broadcast_message_advanced(error_message)

if __name__ == "__main__":
    print("ğŸš€ é–‹å§‹åŸ·è¡Œ LINE æ–°èæ©Ÿå™¨äººï¼ˆQuick Reply ç‰ˆæœ¬ï¼‰")
    print(f"ğŸ“… åŸ·è¡Œæ™‚é–“ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}")
    
    news = fetch_news()
    if any(news_items for news_items in news.values()):
        send_message_by_category(news)
        
        # ğŸ”§ çµ±è¨ˆä¿¡æ¯
        total_news = sum(len(news_items) for news_items in news.values())
        print(f"âœ… æ–°èæ¨æ’­å®Œæˆï¼ç¸½å…±è™•ç† {total_news} å‰‡æ–°è")
        for category, news_items in news.items():
            if news_items:
                print(f"   ğŸ“Š ã€{category}ã€‘: {len(news_items)} å‰‡")
    else:
        print("âš ï¸ æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„æ–°èï¼Œä¸ç™¼é€ã€‚")



